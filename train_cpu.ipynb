{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--name NAME] [--gpu_ids GPU_IDS]\n",
      "                             [--checkpoints_dir CHECKPOINTS_DIR] [--norm NORM]\n",
      "                             [--use_dropout] [--batchSize BATCHSIZE]\n",
      "                             [--loadSize LOADSIZE] [--fineSize FINESIZE]\n",
      "                             [--label_nc LABEL_NC] [--output_nc OUTPUT_NC]\n",
      "                             [--dataroot DATAROOT]\n",
      "                             [--resize_or_crop RESIZE_OR_CROP]\n",
      "                             [--serial_batches] [--no_flip]\n",
      "                             [--nThreads NTHREADS]\n",
      "                             [--max_dataset_size MAX_DATASET_SIZE]\n",
      "                             [--display_winsize DISPLAY_WINSIZE] [--tf_log]\n",
      "                             [--netG NETG] [--ngf NGF]\n",
      "                             [--n_downsample_global N_DOWNSAMPLE_GLOBAL]\n",
      "                             [--n_blocks_global N_BLOCKS_GLOBAL]\n",
      "                             [--n_blocks_local N_BLOCKS_LOCAL]\n",
      "                             [--n_local_enhancers N_LOCAL_ENHANCERS]\n",
      "                             [--niter_fix_global NITER_FIX_GLOBAL]\n",
      "                             [--no_instance] [--instance_feat] [--label_feat]\n",
      "                             [--feat_num FEAT_NUM] [--load_features]\n",
      "                             [--n_downsample_E N_DOWNSAMPLE_E] [--nef NEF]\n",
      "                             [--n_clusters N_CLUSTERS]\n",
      "                             [--display_freq DISPLAY_FREQ]\n",
      "                             [--print_freq PRINT_FREQ]\n",
      "                             [--save_latest_freq SAVE_LATEST_FREQ]\n",
      "                             [--save_epoch_freq SAVE_EPOCH_FREQ] [--no_html]\n",
      "                             [--debug] [--continue_train]\n",
      "                             [--load_pretrain LOAD_PRETRAIN]\n",
      "                             [--which_epoch WHICH_EPOCH] [--phase PHASE]\n",
      "                             [--niter NITER] [--niter_decay NITER_DECAY]\n",
      "                             [--beta1 BETA1] [--lr LR] [--num_D NUM_D]\n",
      "                             [--n_layers_D N_LAYERS_D] [--ndf NDF]\n",
      "                             [--lambda_feat LAMBDA_FEAT] [--no_ganFeat_loss]\n",
      "                             [--no_vgg_loss] [--no_lsgan]\n",
      "                             [--pool_size POOL_SIZE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /Users/blanca.alonso/Library/Jupyter/runtime/kernel-799ad922-ff60-459b-99da-d644df97b163.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blanca.alonso/anaconda3/envs/p3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "### Copyright (C) 2017 NVIDIA Corporation. All rights reserved. \n",
    "### Licensed under the CC BY-NC-SA 4.0 license (https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode).\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from collections import OrderedDict\n",
    "from options.train_options import TrainOptions\n",
    "from data.data_loader import CreateDataLoader\n",
    "from models.models import create_model\n",
    "import util.util as util\n",
    "from util.visualizer import Visualizer\n",
    "\n",
    "opt = TrainOptions().parse()\n",
    "\n",
    "iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')\n",
    "if opt.continue_train:\n",
    "    try:\n",
    "        start_epoch, epoch_iter = np.loadtxt(iter_path , delimiter=',', dtype=int)\n",
    "    except:\n",
    "        start_epoch, epoch_iter = 1, 0\n",
    "    print('Resuming from epoch %d at iteration %d' % (start_epoch, epoch_iter))        \n",
    "else:    \n",
    "    start_epoch, epoch_iter = 1, 0\n",
    "\n",
    "if opt.debug:\n",
    "    opt.display_freq = 1\n",
    "    opt.print_freq = 1\n",
    "    opt.niter = 1\n",
    "    opt.niter_decay = 0\n",
    "    opt.max_dataset_size = 10\n",
    "\n",
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "dataset_size = len(data_loader)\n",
    "print('#training images = %d' % dataset_size)\n",
    "\n",
    "model = create_model(opt)\n",
    "visualizer = Visualizer(opt)\n",
    "\n",
    "total_steps = (start_epoch-1) * dataset_size + epoch_iter    \n",
    "for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    if epoch != start_epoch:\n",
    "        epoch_iter = epoch_iter % dataset_size\n",
    "    for i, data in enumerate(dataset, start=epoch_iter):\n",
    "        iter_start_time = time.time()\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "\n",
    "        # whether to collect output images\n",
    "        save_fake = total_steps % opt.display_freq == 0\n",
    "\n",
    "        ############## Forward Pass ######################\n",
    "        losses, generated = model(Variable(data['label']), Variable(data['inst']), \n",
    "            Variable(data['image']), Variable(data['feat']), infer=save_fake)\n",
    "\n",
    "        # sum per device losses\n",
    "        losses = [ torch.mean(x) if not isinstance(x, int) else x for x in losses ]\n",
    "        loss_dict = dict(zip(model.module.loss_names, losses))\n",
    "\n",
    "        # calculate final loss scalar\n",
    "        loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n",
    "        loss_G = loss_dict['G_GAN'] + loss_dict['G_GAN_Feat'] + loss_dict['G_VGG']\n",
    "\n",
    "        ############### Backward Pass ####################\n",
    "        # update generator weights\n",
    "        model.module.optimizer_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        model.module.optimizer_G.step()\n",
    "\n",
    "        # update discriminator weights\n",
    "        model.module.optimizer_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        model.module.optimizer_D.step()\n",
    "\n",
    "        #call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=memory.used,memory.free\"]) \n",
    "\n",
    "        ############## Display results and errors ##########\n",
    "        ### print out errors\n",
    "        if total_steps % opt.print_freq == 0:\n",
    "            errors = {k: v.data[0] if not isinstance(v, int) else v for k, v in loss_dict.items()}\n",
    "            t = (time.time() - iter_start_time) / opt.batchSize\n",
    "            visualizer.print_current_errors(epoch, epoch_iter, errors, t)\n",
    "            visualizer.plot_current_errors(errors, total_steps)\n",
    "\n",
    "        ### display output images\n",
    "        if save_fake:\n",
    "            visuals = OrderedDict([('input_label', util.tensor2label(data['label'][0], opt.label_nc)),\n",
    "                                   ('synthesized_image', util.tensor2im(generated.data[0])),\n",
    "                                   ('real_image', util.tensor2im(data['image'][0]))])\n",
    "            visualizer.display_current_results(visuals, epoch, total_steps)\n",
    "\n",
    "        ### save latest model\n",
    "        if total_steps % opt.save_latest_freq == 0:\n",
    "            print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "            model.module.save('latest')            \n",
    "            np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n",
    "       \n",
    "    # end of epoch \n",
    "    iter_end_time = time.time()\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "\n",
    "    ### save model for this epoch\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))        \n",
    "        model.module.save('latest')\n",
    "        model.module.save(epoch)\n",
    "        np.savetxt(iter_path, (epoch+1, 0), delimiter=',', fmt='%d')\n",
    "\n",
    "    ### instead of only training the local enhancer, train the entire network after certain iterations\n",
    "    if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\n",
    "        model.module.update_fixed_params()\n",
    "\n",
    "    ### linearly decay learning rate after certain iterations\n",
    "    if epoch > opt.niter:\n",
    "        model.module.update_learning_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
